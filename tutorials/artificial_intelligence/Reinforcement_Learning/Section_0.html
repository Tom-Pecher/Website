<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        <title>Tom Pecher | Portfolio</title>

        <link
            href="https://fonts.googleapis.com/css2?family=Questrial:wght@400;700&display=swap"
            rel="stylesheet"
        />
        <link
            rel="icon"
            type="image/x-icon"
            href="../../../data/profile_picture.jpeg"
        />
        <link rel="stylesheet" href="../../../style.css" />
    </head>

    <body>
        <header>
            <h1>Tom (Tomáš) Pecher</h1>
            <p>
                <b
                    >CS & AI Student | Aspiring Software Developer | Passion for
                    ML and Wolfram</b
                >
            </p>
        </header>

        <nav>
            <ul>
                <li><a href="../../../index.html">Home</a></li>
                <li><a href="../../../skills.html">Skills</a></li>
                <li><a href="../../../AI.html">AI</a></li>
                <!-- <li><a href="wolfram.html">Wolfram</a></li> -->
                <!-- <li><a href="mandarin.html">Mandarin</a></li> -->
                <li><a href="../../../achievements.html">Achievements</a></li>
                <li><a href="../../../contact.html">Contact</a></li>
            </ul>
        </nav>

        <section class="triangle-grid">
            <h2>Reinforcement Learning: Course Introduction</h2>
            <p>
                Reinforcement learning (RL) is often considered the odd-one-out of the three subfields of AI, as its principles and methodology of using data is quite different from supervised and unsupervised learning.
                The goal of RL is to develop agents (algorithms that can act) that make decisions based on interactions with an environment, is popularly defined as "a goal-driven approach to decision making problems".
                Theoretically speaking however, RL can be best described as a data-driven extension of markov decision processes (MDPs), (see <a href="../Traditional_AI/Section_0.html">Tranditional AI</a>).
                In the RL paradigm, an agent can move between environmental states through actions and receive rewards based on the current state.
                The goal of designing an RL algorithm is to create agents that maximise the sum of these rewards over time.
                Despite the simple premise, this paradigm can be applied to a variety of problems, with different algorithms and techniques.
                In many ways, RL is the most intuitive of the three subfields of ML, as we can generally make sense of the strategies produced by the algorithms, even as deep learning becomes more involved.

                <br/>
                <br/>
                <h3>Course Structure:</h3>

                <ul>
                    <li><a href="Section_1.html">Section 1: Foundations and Prerequisites</a></li>
                    <li><a href="Section_2.html">Section 2: Markov Decision Processes</a></li> 
                    <li>Section 3: Dynamic Programming</li>
                    <li>Section 4: Reinforcement Learning Paradigm</li>
                    <li>Section 5: Temporal Difference Learning</li>
                    <li>Section 6: Function Approximation</li>
                    <li>Section 7: Deep Reinforcement Learning</li>
                    <li>Section 8: Advanced Deep RL Architectures</li>
                    <li>Section 9: Model-Based Reinforcement Learning</li>
                    <li>Section 10: Multi-Agent Reinforcement Learning</li>
                    <li>Section 11: Hierarchical Reinforcement Learning</li>
                    <li>Section 12: Exploration-Exploitation Strategies</li>
                    <li>Section 13: Imitation and Inverse Reinforcement Learning</li>
                    <li>Section 14: Safe and Robust Reinforcement Learning</li>
                    <li>Section 15: Transfer and Meta Reinforcement Learning</li>
                    <li>Section 16: Offline Reinforcement Learning</li>
                    <li>Section 17: Distributed and Scalable Reinforcement Learning</li>
                    <li>Section 18: Special Applications and Domains</li>
                </ul>
            </p>

            <br>
            <p>
                <em><a href="../Home.html">Back to AI Courses...</a></em>
            </p>

            <br>
            <br>
            <div class="grid-buttons" style="overflow-x:auto;">
                <div class="grid-button section-button-4" style="pointer-events: none; background-color: #c451d8;">Previous</div>
                <a href="Section_0.html" class="grid-button section-button-4">Course Home</a>
                <a href="Section_1.html" class="grid-button section-button-4">Next</a>
            </div>

        </section>

        <footer>
            <p>Connect with me on <a href="https://github.com/Tom-Pecher" target="_blank">GitHub</a></p>
            <em><p>Updated on <span id="last-updated"></span></p></em>
        </footer>
    
    </body>
    
    
    
    <script>
        const lastModified = new Date(document.lastModified);
        document.getElementById("last-updated").textContent = lastModified.toLocaleDateString();
    </script>



</html>
